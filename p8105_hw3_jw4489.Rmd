---
title: "p8105_hw3_jw4489"
output: github_document
date: "2023-10-12"
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

##### Look at data.

```{r}
library(p8105.datasets)
data("instacart")

instacart = 
  instacart |> 
  as_tibble()

view(instacart)
```

##### Describe the data.

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. Each row represents a product from an instacart order. The dataset contains various variables, including "order_id", "product_id", "add_to_cart_order", "reordered", "user_id", "eval_set", "order_number", "order_row", "order_hour_of_day", etc. From these variables, several variables are order-level, meaning that they describe the day and time of the order, and number of days since prior order. And there are also several item-specific variables. These item-specific variables describe the product names (e.g. Bulgarian Yogurt, Spring Water), department of the products (e.g. dairy eggs, beverages), and aisles (e.g. yogurt, water seltzer sparkling water), and whether the item has been ordered by this user in the past. There are `r instacart |> select(product_id) |> distinct() |> count()` products found in `r instacart |> select(user_id, order_id) |> distinct() |> count()` orders from `r instacart |> select(user_id) |> distinct() |> count()` distinct users in total.

##### Answer the questions.

```{r}
instacart |> 
  count(aisle) |> 
  arrange(desc(n))
```

There are 134 aisles. Fresh vegetables and fresh fruits are the aisles that the most items ordered from.

```{r}
instacart |> 
  count(aisle) |> 
  filter(n > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

The plot is made, with the number of items ordered in each aisle. And aisles are ordered by ascending number of items following the instruction.

```{r}
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable()
```

The table is made. It shows the three most popular items in aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, and includes the number of times each item is ordered in the table.

```{r}
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) |>
  knitr::kable(digits = 2)
```

The table is made. It shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. This table has been formatted in an untidy manner for human readers. Pink Lady Apples are generally purchased slightly earlier in the day than Coffee Ice Cream, with the exception of day 5.

## Problem 2

###### Look at data and do some data cleaning.

```{r}
data("brfss_smart2010")

brfss = 
  brfss_smart2010 |> 
  janitor::clean_names() |>
  filter(
    topic == "Overall Health",
    response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")
    ) |>
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE)
    )

view(brfss)
```

##### Answer the questions.

```{r}
observed_2002 = brfss |>
  group_by(year, locationabbr) |>
  summarize(count = n_distinct(locationdesc), .groups = "drop") |>
  filter(year == 2002, count  >=7) |>
  arrange(desc(count)) |>
  knitr::kable(col.names = c("Year_Observed", "State_Observed", "Counts"),
               caption = "States that were observed at 7 or more locations in 2002")

observed_2010 = brfss |>
  group_by(year, locationabbr) |>
  summarize(count = n_distinct(locationdesc), .groups = "drop") |>
  filter(year == 2010, count  >=7) |>
  arrange(desc(count)) |>
  knitr::kable(col.names = c("Year_Observed", "State_Observed", "Counts"),
               caption = "States that were observed at 7 or more locations in 2010")

observed_2002
observed_2010
```

According to two tables generated above, we know that PA, MA, NJ, CT, FL, NC were observed at 7 or more locations in 2002. In 2010, FL, NJ, TX, CA, MD, NC, NE, WA, MA, NY, OH, CO, PA, SC were observed at 7 or more locations.

```{r}
excellent_response = brfss |>
  filter(response == "Excellent") |>
  group_by(year, locationabbr) |>
  summarize(average = mean(data_value), .groups = "drop") |>
  ggplot(aes(x = year, y = average, group = locationabbr, color = locationabbr)) + 
  geom_line()+
  labs(title = "Average Values Over Time Within a State",
       x = "Year",
       y = "Average Values") +
  theme_minimal()

excellent_response
```

The dataset is constructed and the “spaghetti” plot is made. The dataset includes year, states, and average values of "excellent" responses over time within each state, and the plot is valuable and useful in providing information to the audience. According to the "spaghetti" plot, we can intuitively see that the average values of "excellent" responses present a downward trend overall. And we can also clearly see and compare each state's average value of "excellent" responses over time. 

```{r}
ny_value = brfss |>
  filter(locationabbr == "NY",
         year %in% c("2006", "2010"),
         response %in% c("Poor", "Fair", "Good", "Very good", "Excellent"))

ny_plot = ny_value |>
  ggplot(aes(x = response, y = data_value, color = response)) +
  geom_point(alpha = 0.5) +
  facet_grid(. ~ year) +
  labs(
    title = "Distribution of data_value for Responses for 2006 and 2010",
    x = "Response Level",
    y = "Data Value"
  ) +
  theme_minimal() 

ny_plot
```

## Problem 3






